{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fc13fcf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/snranepuradewage/.lico_env/jupyter/env/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "#import packages\n",
    "import os, csv, time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from PIL import Image, ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import autocast\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from timm.models import create_model\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "from livelossplot import PlotLosses\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "81eaf011",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_DIR = os.path.join(\"/users/snranepuradewage/roco_multimodal/baseline/models_concept/\")\n",
    "filenameCSV=MODEL_DIR+\"EfficientNetB0_perform.csv\"\n",
    "DATA_DIR=\"/users/snranepuradewage/roco-dataset-master/data-master\"\n",
    "data_train=DATA_DIR+\"/train/\"\n",
    "data_valid=DATA_DIR+\"/valid/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a8d294f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load dataset with IDs\n",
    "df_train=pd.read_csv(DATA_DIR+\"/train_concepts.csv\",sep=\",\")\n",
    "df_valid=pd.read_csv(DATA_DIR+\"/valid_concepts.csv\",sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "28ed1d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train[\"image_path\"]=data_train+df_train.ID+\".jpg\"\n",
    "df_valid[\"image_path\"]=data_valid+df_valid.ID+\".jpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8f27fa30",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_merged=pd.concat([df_train,df_valid])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ef7732ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "cuis_list=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9ad33c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "for (i,row) in df_train_merged.iterrows():\n",
    "    for cui in row[\"CUIs\"].split(\";\"):\n",
    "        if not cui in cuis_list:\n",
    "            cuis_list.append(cui)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b06d1e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(MODEL_DIR):\n",
    "    os.makedirs(MODEL_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b7e7f50a",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLASSES=len(cuis_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "11df7ef8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total unique CUIs: 1947\n"
     ]
    }
   ],
   "source": [
    "print(\"Total unique CUIs:\", len(cuis_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eaf78421",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ROCOv2Dataset(Dataset):\n",
    "    def __init__(self, data, transform=None):\n",
    "        self.data = data\n",
    "        self.transform = transform # Image augmentation pipeline\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.data.shape[0]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        obj = self.data.iloc[index] # get instance\n",
    "        label = obj.CUIs # get label\n",
    "        label_enc=torch.zeros((NUM_CLASSES))\n",
    "        for cui in label.split(\";\"):\n",
    "            label_enc[cuis_list.index(cui)]=1\n",
    "        # img. augmentation\n",
    "        img = Image.open(obj.image_path).convert(\"RGB\") # load image\n",
    "        img = self.transform(img)\n",
    "\n",
    "        return (img, label_enc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6073d7fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class IdentityTransform:\n",
    "    def __call__(self, x):\n",
    "        return x\n",
    "\n",
    "\n",
    "# train data augmentation/ preprocessing pipeline\n",
    "def get_train_augmentation_preprocessing(img_size, rand_aug=False):\n",
    "    print(f'IMG_SIZE_TRAIN: {img_size}, RandAug: {rand_aug}')\n",
    "    return transforms.Compose([\n",
    "                transforms.Resize(int(img_size * 1.25)), # Expand IMAGE_SIZE before random crop\n",
    "                #RandomGridShuffle(grid=TRANSFORMS['n_grid']),\n",
    "                transforms.RandomHorizontalFlip(p=0.5),\n",
    "                transforms.RandomVerticalFlip(p=0.5),\n",
    "                transforms.RandomCrop((img_size, img_size)), # Random Crop to IMAGE_SIZE\n",
    "                #transforms.RandAugment(num_ops=2, magnitude=9) if rand_aug else IdentityTransform(),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
    "            ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0df3e640",
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffle\n",
    "df_train_merged = df_train_merged.sample(frac=1, random_state=1).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1046efb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgsize_train=224\n",
    "imgsize_val=224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b480e630",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMG_SIZE_TRAIN: 224, RandAug: True\n"
     ]
    }
   ],
   "source": [
    "train_aug_preprocessing = get_train_augmentation_preprocessing(imgsize_train, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "afbe456c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset= ROCOv2Dataset(df_train_merged, transform = train_aug_preprocessing)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "72c6ebb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE=256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "58d1d630",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(dataset = train_dataset, shuffle = True, batch_size = BATCH_SIZE, num_workers = 9, drop_last = True, pin_memory = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62105780",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_41793/4069333915.py:5: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = torch.cuda.amp.GradScaler(enabled=use_amp)\n",
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20 | Loss: 0.0001 | F1: 0.2911 | Time: 102.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/20 | Loss: 0.0000 | F1: 0.5383 | Time: 103.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/20 | Loss: 0.0000 | F1: 0.5614 | Time: 129.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/20 | Loss: 0.0000 | F1: 0.5740 | Time: 120.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/20 | Loss: 0.0000 | F1: 0.5804 | Time: 124.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [6/20]:   0%|          | 1/272 [00:01<08:32,  1.89s/it]"
     ]
    }
   ],
   "source": [
    "m = nn.Sigmoid()\n",
    "lr=0.001\n",
    "opt=\"adam\"\n",
    "use_amp = True\n",
    "scaler = torch.cuda.amp.GradScaler(enabled=use_amp)\n",
    "batchsize_factor=1\n",
    "val_interval = 1\n",
    "epoch_loss_values = []\n",
    "max_epochs = 20\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model=create_model('efficientnet_b0', pretrained=True, num_classes=NUM_CLASSES, drop_path_rate=0.2)\n",
    "loss_function = torch.nn.MultiLabelSoftMarginLoss()\n",
    "if opt ==\"adam\":\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "elif opt==\"sgd\":\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
    "else:\n",
    "    optimizer = torch.optim.RMSprop(model.parameters(), lr=lr)\n",
    "model = model.to(device)\n",
    "for epoch in range(max_epochs):\n",
    "    start_time = time.time()\n",
    "    model.train()\n",
    "    logs = {}\n",
    "    epoch_loss = 0\n",
    "    epoch_loss_val = 0\n",
    "    step = 0\n",
    "    labels_sum = np.empty([0, NUM_CLASSES])\n",
    "    pred_sum = np.empty([0, NUM_CLASSES])\n",
    "    labels_sum_val = np.empty([0, NUM_CLASSES])\n",
    "    pred_sum_val = np.empty([0, NUM_CLASSES])\n",
    "    \n",
    "    for batch_idx, (inputs, labels) in enumerate(\n",
    "        tqdm(train_loader, desc=f\"Epoch [{epoch+1}/{max_epochs}]\", leave=False)):\n",
    "        step += 1\n",
    "        inputs = inputs.cuda()\n",
    "        labels = labels.cuda()\n",
    "        with autocast(device_type = 'cuda', enabled = True): \n",
    "            outputs = model(inputs)\n",
    "            loss = loss_function(outputs, labels)\n",
    "            loss = loss / batchsize_factor\n",
    "            scaler.scale(loss).backward()\n",
    "            output_sig = m(outputs)\n",
    "            output_sig_class = (output_sig >= 0.5).long()\n",
    "        if (step + 1) % batchsize_factor == 0:\n",
    "            scaler.unscale_(optimizer)\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "        epoch_loss += (loss.item() * batchsize_factor)\n",
    "        epoch_len = len(train_dataset) // train_loader.batch_size\n",
    "        labels_sum = np.append(labels_sum, labels.detach().cpu().numpy(), axis = 0)\n",
    "\n",
    "        pred_sum = np.append(pred_sum, output_sig_class.detach().cpu().numpy(), axis = 0)\n",
    "\n",
    "    logs['log loss'] = epoch_loss / len(train_dataset)\n",
    "    logs['F1 macro'] = f1_score(labels_sum.T, pred_sum.T, average = 'macro')\n",
    "    epoch_loss_values.append(epoch_loss)\n",
    "    \n",
    "    torch.save(model.state_dict(), MODEL_DIR + \"model_\" + str(opt) + \"_\" + str(lr) + \"_\" + str(epoch) + \".pth\")\n",
    "    \n",
    "    elapsed = time.time() - start_time\n",
    "    print(f\"Epoch {epoch+1}/{max_epochs} | Loss: {logs['log loss']:.4f} | F1: {logs['F1 macro']:.4f} | Time: {elapsed:.1f}s\")\n",
    "    \n",
    "    with open(filenameCSV, \"a\", newline=\"\") as f:\n",
    "        csv.writer(f).writerow([epoch + 1, logs['log loss'], logs['F1 macro'], elapsed])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f913d0e5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
